{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Two-wave RPS Algorithm",
   "id": "3821486d2362d731"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:28:25.362429Z",
     "start_time": "2025-06-21T04:28:25.350812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rashomon.hasse import enumerate_policies\n",
    "from rashomon.aggregate import RAggregate\n",
    "from first_wave import compute_boundary_probs, allocate_wave, assign_first_wave_treatments\n",
    "from data_gen import get_beta_underlying_causal, generate_outcomes"
   ],
   "id": "5242302164f6663e",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. First-wave allocation",
   "id": "df6535a12f16459b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:28:39.370951Z",
     "start_time": "2025-06-21T04:28:39.363781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get lattice\n",
    "M = 4\n",
    "R = 3\n",
    "R_vec = np.full(M, R) if np.isscalar(R) else np.array(R) # allow for heterogeneity in levels\n",
    "assert R_vec.shape == (M,)\n",
    "policies = enumerate_policies(M, R)\n",
    "K = len(policies)\n",
    "print(f\"Found K = {K} policies (each policy is an {M}-tuple).\")\n",
    "H = 5  # sparsity parameter used inside compute_boundary_probs TODO choice\n",
    "n1 = 500  # total first‐wave sample size"
   ],
   "id": "193da5cfc81258b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found K = 81 policies (each policy is an 4-tuple).\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Compute first‐wave allocation**: We need R_i for each feature (here R_i = R for i=0,…,M-1), then we call `compute_boundary_probs` -> `allocate_first_wave`. We get `n1_alloc`: an array of length K summing to n1.",
   "id": "c7c2ae3f8cef0d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:28:40.880521Z",
     "start_time": "2025-06-21T04:28:40.873800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "boundary_probs = compute_boundary_probs(policies, R, H)\n",
    "n1_alloc = allocate_wave(boundary_probs, n1)\n",
    "print(f\"First‐wave allocation sums to {int(n1_alloc.sum())} (should be {n1}).\")"
   ],
   "id": "6dcc0a9d2d342815",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First‐wave allocation sums to 500 (should be 500).\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Simulating first-wave outcomes",
   "id": "db2cf32df91f077f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We generate a np.array `beta` of true effects for each node. We pass our lattice `policies`, `M` and `R`, and then specify a `kind` of underlying causal model.\n",
    "\n",
    "There are a range of options, all of which are continuous and non-trivial: they exhibit locally correlated effects and avoid brittle cancellations in effects. The options range from simple (polynomial, gaussian, basic interaction) to complex (radial basis function, mimic of a simple neural-net-like function)"
   ],
   "id": "783d2bf35aa2605f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:28:51.532975Z",
     "start_time": "2025-06-21T04:28:51.524977Z"
    }
   },
   "cell_type": "code",
   "source": "beta = get_beta_underlying_causal(policies, M, R, kind=\"gauss_sin\")",
   "id": "37f3b09738cfdc4e",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:28:51.748455Z",
     "start_time": "2025-06-21T04:28:51.744056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Not in use: different distribution for each true pool from a random 'true' partition sigma_true. Not used in this simulation due to our specifications on the underlying causal model (e.g. continuous, locally correlated effects, etc). Also needs changes on how it constructs a true partition.\n",
    "\n",
    "# partition_seed = 123\n",
    "# sigma_true, pi_pools_true, pi_policies_true = generate_true_partition(policies, R,random_seed=partition_seed)\n",
    "# beta = get_beta_piecewise(policies, sigma_true, pi_pools_true, pi_policies_true, 0.5, 1, 10)"
   ],
   "id": "c0124dca96a59a16",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Get outcomes**: we now track the first-wave assignment and generate the outcomes with additional noise",
   "id": "96414d2d89e71d3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:28:53.437071Z",
     "start_time": "2025-06-21T04:28:53.431969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now build first-wave assignment vector D\n",
    "D1 = assign_first_wave_treatments(n_alloc=n1_alloc) # TODO check dimensions here\n",
    "N1 = D1.shape[0]\n",
    "\n",
    "print(\"Length of D1:\", N1)  # should equal sum n1_alloc == n1"
   ],
   "id": "4cb7d7c5a1785390",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of D1: 500\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:28:54.528938Z",
     "start_time": "2025-06-21T04:28:54.516219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate outcomes y1\n",
    "sigma_noise = 5\n",
    "outcome_seed = 53\n",
    "y1 = generate_outcomes(D=D1, beta=beta, sigma_noise=sigma_noise, random_seed=outcome_seed)\n",
    "\n",
    "print(\"Overall mean outcome:\", np.mean(y1))\n",
    "print(\"Overall std outcome:\", np.std(y1))"
   ],
   "id": "a9a34a6d63a9e449",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean outcome: -0.06186879481060036\n",
      "Overall std outcome: 5.345327463311591\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. RPS for profiles with data",
   "id": "d65ec763ab104f39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We now search for the optimal theta as given by a normalized loss and chosen epsilon. Need to already specify H and the regularization parameter.",
   "id": "30fbf3ae778f228f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:29:08.623768Z",
     "start_time": "2025-06-21T04:29:08.618158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lambda_r = 0.3\n",
    "eps = 0.05 # chosen tolerance"
   ],
   "id": "bf3efc3328c7bf10",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:29:08.905624Z",
     "start_time": "2025-06-21T04:29:08.901938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from rashomon.hasse import enumerate_policies, enumerate_profiles, policy_to_profile\n",
    "from rashomon.aggregate import (\n",
    "    RAggregate_profile,\n",
    "    find_feasible_combinations,\n",
    "    subset_data,\n",
    "    find_profile_lower_bound\n",
    ")\n",
    "from rashomon import loss"
   ],
   "id": "6dbeb16e2bb5cc0f",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:29:09.443445Z",
     "start_time": "2025-06-21T04:29:09.436456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Enumerate profiles and map policies to each\n",
    "profiles, profile_map = enumerate_profiles(M)\n",
    "all_policies = enumerate_policies(M, R_vec)\n",
    "\n",
    "profile_to_policies = {}\n",
    "profile_to_indices = {}\n",
    "for i, pol in enumerate(all_policies):\n",
    "    pid = profile_map[policy_to_profile(pol)]\n",
    "    profile_to_policies.setdefault(pid, []).append(pol)\n",
    "    profile_to_indices.setdefault(pid, []).append(i)"
   ],
   "id": "d30d48d97739eb63",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We now filter for the profiles just with any data.",
   "id": "b79afcee8eee6bfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:29:12.668248Z",
     "start_time": "2025-06-21T04:29:12.634914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2: Filter profiles with data and compute normalized lower-bound losses\n",
    "valid_pids = []\n",
    "lb_k = []  # normalized lower-bound loss for each valid profile\n",
    "\n",
    "for pid, profile in enumerate(profiles):\n",
    "    Dk, yk = subset_data(D1, y1, profile_to_indices[pid])\n",
    "    if Dk is None:\n",
    "        continue\n",
    "    mask = np.array(profile, dtype=bool)\n",
    "    reduced_policies = [tuple(np.array(p)[mask]) for p in profile_to_policies[pid]]\n",
    "    pm = loss.compute_policy_means(Dk, yk, len(reduced_policies))\n",
    "    raw_lb = find_profile_lower_bound(Dk, yk, pm)\n",
    "    lb_k.append(raw_lb / N1)\n",
    "    valid_pids.append(pid)\n",
    "\n",
    "lb_k = np.array(lb_k)                   # array of normalized lower bounds\n",
    "best_loss = lb_k.min()                 # best profile loss\n",
    "total_lb = lb_k.sum()\n",
    "theta_global = total_lb * (1 + eps) # Theta is in reference to total loss here, not a relative value\n",
    "print(f\"best_loss = {best_loss:.5f}\")\n",
    "print(f\"theta_global = {theta_global:.5f}\")"
   ],
   "id": "8e89eb7377549fa2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_loss = 0.09952\n",
      "theta_global = 25.23455\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We now construct the RPS for each profile with data from our first allocation.",
   "id": "d090de1185f966ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:29:14.022219Z",
     "start_time": "2025-06-21T04:29:13.967753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "R_profiles = []\n",
    "loss_args = []\n",
    "\n",
    "for i, pid in enumerate(valid_pids):\n",
    "    profile_mask = np.array(profiles[pid], dtype=bool)\n",
    "    M_k = profile_mask.sum()\n",
    "    R_k = R_vec[profile_mask]\n",
    "\n",
    "    Dk, yk = subset_data(D1, y1, profile_to_indices[pid])\n",
    "    reduced_policies = [tuple(np.array(p)[profile_mask]) for p in profile_to_policies[pid]]\n",
    "    pm = loss.compute_policy_means(Dk, yk, len(reduced_policies))\n",
    "\n",
    "    theta_k = max(0.0, theta_global - (total_lb - lb_k[i]))\n",
    "\n",
    "    print(f\"Calling RAggregate_profile on profile {pid}, M_k={M_k}, len(policies)={len(reduced_policies)}, theta_k={theta_k:.5f}\")\n",
    "    print(f\": lower_bound: {lb_k[i]:.5f}, theta_k: {theta_k:.5f}\")\n",
    "\n",
    "    rp = RAggregate_profile(\n",
    "        M=M_k,\n",
    "        R=R_k,\n",
    "        H=H,\n",
    "        D=Dk,\n",
    "        y=yk,\n",
    "        theta=theta_k,\n",
    "        profile=tuple(profiles[pid]),\n",
    "        reg=lambda_r,\n",
    "        policies=reduced_policies,\n",
    "        policy_means=pm,\n",
    "        normalize=N1\n",
    "    )\n",
    "\n",
    "    print(f\": RPS size for profile {pid}: {len(rp)}\")\n",
    "    if len(rp) > 0:\n",
    "        R_profiles.append(rp)\n",
    "        loss_args.append((Dk, yk, reduced_policies, pm))"
   ],
   "id": "d864d078a9c1d824",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling RAggregate_profile on profile 1, M_k=1, len(policies)=2, theta_k=1.85380\n",
      ": lower_bound: 0.65216, theta_k: 1.85380\n",
      ": RPS size for profile 1: 2\n",
      "Calling RAggregate_profile on profile 2, M_k=1, len(policies)=2, theta_k=1.55939\n",
      ": lower_bound: 0.35774, theta_k: 1.55939\n",
      ": RPS size for profile 2: 2\n",
      "Calling RAggregate_profile on profile 3, M_k=2, len(policies)=4, theta_k=2.28029\n",
      ": lower_bound: 1.07864, theta_k: 2.28029\n",
      ": RPS size for profile 3: 4\n",
      "Calling RAggregate_profile on profile 4, M_k=1, len(policies)=2, theta_k=1.30117\n",
      ": lower_bound: 0.09952, theta_k: 1.30117\n",
      ": RPS size for profile 4: 2\n",
      "Calling RAggregate_profile on profile 5, M_k=2, len(policies)=4, theta_k=2.28977\n",
      ": lower_bound: 1.08812, theta_k: 2.28977\n",
      ": RPS size for profile 5: 4\n",
      "Calling RAggregate_profile on profile 6, M_k=2, len(policies)=4, theta_k=1.79353\n",
      ": lower_bound: 0.59188, theta_k: 1.79353\n",
      ": RPS size for profile 6: 4\n",
      "Calling RAggregate_profile on profile 7, M_k=3, len(policies)=8, theta_k=3.94933\n",
      ": lower_bound: 2.74769, theta_k: 3.94933\n",
      ": RPS size for profile 7: 0\n",
      "Calling RAggregate_profile on profile 8, M_k=1, len(policies)=2, theta_k=1.40522\n",
      ": lower_bound: 0.20357, theta_k: 1.40522\n",
      ": RPS size for profile 8: 2\n",
      "Calling RAggregate_profile on profile 9, M_k=2, len(policies)=4, theta_k=2.09451\n",
      ": lower_bound: 0.89287, theta_k: 2.09451\n",
      ": RPS size for profile 9: 4\n",
      "Calling RAggregate_profile on profile 10, M_k=2, len(policies)=4, theta_k=2.19088\n",
      ": lower_bound: 0.98924, theta_k: 2.19088\n",
      ": RPS size for profile 10: 4\n",
      "Calling RAggregate_profile on profile 11, M_k=3, len(policies)=8, theta_k=2.85936\n",
      ": lower_bound: 1.65772, theta_k: 2.85936\n",
      ": RPS size for profile 11: 0\n",
      "Calling RAggregate_profile on profile 12, M_k=2, len(policies)=4, theta_k=2.26666\n",
      ": lower_bound: 1.06502, theta_k: 2.26666\n",
      ": RPS size for profile 12: 4\n",
      "Calling RAggregate_profile on profile 13, M_k=3, len(policies)=8, theta_k=2.97691\n",
      ": lower_bound: 1.77527, theta_k: 2.97691\n",
      ": RPS size for profile 13: 0\n",
      "Calling RAggregate_profile on profile 14, M_k=3, len(policies)=8, theta_k=3.89039\n",
      ": lower_bound: 2.68874, theta_k: 3.89039\n",
      ": RPS size for profile 14: 0\n",
      "Calling RAggregate_profile on profile 15, M_k=4, len(policies)=16, theta_k=9.34637\n",
      ": lower_bound: 8.14473, theta_k: 9.34637\n",
      ": RPS size for profile 15: 0\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:29:15.782573Z",
     "start_time": "2025-06-21T04:29:15.767521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute loss only for nonempty profile RPSs\n",
    "for rp, (Dk, yk, policies_k, pm_k) in zip(R_profiles, loss_args):\n",
    "    rp.calculate_loss(Dk, yk, policies_k, pm_k, lambda_r, normalize=N1)"
   ],
   "id": "3fa23bf50b57be30",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Construct the full RPS",
   "id": "39a3c974e7fa947e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We demonstrate the creation of the full RPS from the profile-specific partitions.",
   "id": "bd9c8723d19ab924"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:26:45.492805Z",
     "start_time": "2025-06-21T04:26:45.270890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from observed_RPS import RAggregate_observed_space\n",
    "R_set_obs, R_profiles_obs, valid_pids, profiles = RAggregate_observed_space(\n",
    "    M, R_vec, H, D1, y1, lambda_r, 0.05, True\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"\\nNumber of feasible global Rashomon sets: {len(R_set_obs)}\")\n",
    "print(f\"Number of observed profiles: {len(valid_pids)}\")\n",
    "for i, pid in enumerate(valid_pids):\n",
    "    print(f\"Profile {pid}: size {len(R_profiles_obs[i])}\")"
   ],
   "id": "4f1cc322291fe542",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[59]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mobserved_RPS\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m RAggregate_observed_space\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m R_set_obs, R_profiles_obs, valid_pids, profiles = \u001B[43mRAggregate_observed_space\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[43mM\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mR_vec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mD1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlambda_r\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0.05\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[32m      4\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mNumber of feasible global Rashomon sets: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(R_set_obs)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mNumber of observed profiles: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(valid_pids)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Documents/rps_projects/adaptive-exp-rps/two-wave/simulation/observed_RPS.py:29\u001B[39m, in \u001B[36mRAggregate_observed_space\u001B[39m\u001B[34m(M, R_vec, H, D, y, lambda_reg, eps, verbose)\u001B[39m\n\u001B[32m     27\u001B[39m indices = policy_to_indices[pid]\n\u001B[32m     28\u001B[39m \u001B[38;5;66;03m# D1 indices must be for policy assignment, not all_policies!\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m29\u001B[39m idx_mask = np.isin(\u001B[43mD\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m, indices)\n\u001B[32m     30\u001B[39m Dk = D[idx_mask]\n\u001B[32m     31\u001B[39m yk = y[idx_mask]\n",
      "\u001B[31mIndexError\u001B[39m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We demonstrate a main wrapper call, as we would use from the original Rashomon module, but we note that the function operates unexpectedly because we don't have data for a number of the profiles. (We end up with an empty Rashomon Partition Set).",
   "id": "550fb5a98dfcbeb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T04:24:48.708272Z",
     "start_time": "2025-06-21T04:24:47.776452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Doesn't work!! Because only have data on a small subspace, and quits out when we can't make a pooling decision\n",
    "# Call main RAggregate function\n",
    "R_set, R_profiles = RAggregate(\n",
    "    M=M,\n",
    "    R=R_vec,\n",
    "    H=H,\n",
    "    D=D1,\n",
    "    y=y1,\n",
    "    theta=theta,\n",
    "    reg=lambda_r,\n",
    "    verbose=True,\n",
    ")"
   ],
   "id": "c61165e5ea76d402",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping profile (0, 0, 0, 0)\n",
      "(0, 0, 0, 1) 1.8538012790890122\n",
      "Adaptive\n",
      "Profile (0, 0, 0, 1) took 9.512901306152344e-05 s adaptively\n",
      "Profile (0, 0, 0, 1) has 0 objects in Rashomon set\n",
      "(0, 0, 1, 0) 1.5593901884315748\n",
      "Adaptive\n",
      "Profile (0, 0, 1, 0) took 3.814697265625e-05 s adaptively\n",
      "Profile (0, 0, 1, 0) has 0 objects in Rashomon set\n",
      "(0, 0, 1, 1) 2.28028641407721\n",
      "Adaptive\n",
      "Profile (0, 0, 1, 1) took 5.0067901611328125e-05 s adaptively\n",
      "Profile (0, 0, 1, 1) has 0 objects in Rashomon set\n",
      "(0, 1, 0, 0) 1.3011691608719111\n",
      "Adaptive\n",
      "Profile (0, 1, 0, 0) took 3.361701965332031e-05 s adaptively\n",
      "Profile (0, 1, 0, 0) has 0 objects in Rashomon set\n",
      "(0, 1, 0, 1) 2.289768913383508\n",
      "Adaptive\n",
      "Profile (0, 1, 0, 1) took 3.504753112792969e-05 s adaptively\n",
      "Profile (0, 1, 0, 1) has 0 objects in Rashomon set\n",
      "(0, 1, 1, 0) 1.7935284046560085\n",
      "Adaptive\n",
      "Profile (0, 1, 1, 0) took 3.218650817871094e-05 s adaptively\n",
      "Profile (0, 1, 1, 0) has 0 objects in Rashomon set\n",
      "(0, 1, 1, 1) 3.9493318341276833\n",
      "Adaptive\n",
      "Profile (0, 1, 1, 1) took 3.600120544433594e-05 s adaptively\n",
      "Profile (0, 1, 1, 1) has 0 objects in Rashomon set\n",
      "(1, 0, 0, 0) 1.4052157090962432\n",
      "Adaptive\n",
      "Profile (1, 0, 0, 0) took 2.6941299438476562e-05 s adaptively\n",
      "Profile (1, 0, 0, 0) has 0 objects in Rashomon set\n",
      "(1, 0, 0, 1) 2.094512312021216\n",
      "Adaptive\n",
      "Profile (1, 0, 0, 1) took 2.8848648071289062e-05 s adaptively\n",
      "Profile (1, 0, 0, 1) has 0 objects in Rashomon set\n",
      "(1, 0, 1, 0) 2.1908842027722812\n",
      "Adaptive\n",
      "Profile (1, 0, 1, 0) took 2.8848648071289062e-05 s adaptively\n",
      "Profile (1, 0, 1, 0) has 0 objects in Rashomon set\n",
      "(1, 0, 1, 1) 2.85936123868969\n",
      "Adaptive\n",
      "Profile (1, 0, 1, 1) took 3.409385681152344e-05 s adaptively\n",
      "Profile (1, 0, 1, 1) has 0 objects in Rashomon set\n",
      "(1, 1, 0, 0) 2.26666104144115\n",
      "Adaptive\n",
      "Profile (1, 1, 0, 0) took 3.0994415283203125e-05 s adaptively\n",
      "Profile (1, 1, 0, 0) has 0 objects in Rashomon set\n",
      "(1, 1, 0, 1) 2.976914494934011\n",
      "Adaptive\n",
      "Profile (1, 1, 0, 1) took 3.409385681152344e-05 s adaptively\n",
      "Profile (1, 1, 0, 1) has 0 objects in Rashomon set\n",
      "(1, 1, 1, 0) 3.8903859379439254\n",
      "Adaptive\n",
      "Profile (1, 1, 1, 0) took 3.2901763916015625e-05 s adaptively\n",
      "Profile (1, 1, 1, 0) has 0 objects in Rashomon set\n",
      "(1, 1, 1, 1) 9.346371021948757\n",
      "Adaptive\n",
      "Profile (1, 1, 1, 1) took 4.00543212890625e-05 s adaptively\n",
      "Profile (1, 1, 1, 1) has 0 objects in Rashomon set\n",
      "Finding feasible combinations\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a9a8786b1fc33312",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
