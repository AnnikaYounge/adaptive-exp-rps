{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Two-wave RPS Algorithm",
   "id": "3821486d2362d731"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:26.771325Z",
     "start_time": "2025-06-21T17:49:25.937093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from rashomon.hasse import enumerate_policies\n",
    "from rashomon.aggregate import RAggregate\n",
    "from allocation import compute_boundary_probs, allocate_wave, assign_treatments\n",
    "from data_gen import get_beta_underlying_causal, generate_outcomes"
   ],
   "id": "5242302164f6663e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. First-wave allocation",
   "id": "df6535a12f16459b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:27.097223Z",
     "start_time": "2025-06-21T17:49:27.092945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get lattice\n",
    "M = 3\n",
    "R = 4\n",
    "\n",
    "R_vec = np.full(M, R) if np.isscalar(R) else np.array(R) # allow for heterogeneity in levels\n",
    "assert R_vec.shape == (M,)\n",
    "policies = enumerate_policies(M, R)\n",
    "\n",
    "K = len(policies)\n",
    "print(f\"Found K = {K} policies (each policy is an {M}-tuple).\")\n",
    "H = 5  # sparsity parameter used inside compute_boundary_probs TODO choice\n",
    "n1 = 500  # total first‐wave sample size"
   ],
   "id": "193da5cfc81258b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found K = 64 policies (each policy is an 3-tuple).\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Compute first‐wave allocation**: We need R_i for each feature (here R_i = R for i=0,…,M-1), then we call `compute_boundary_probs` -> `allocate_first_wave`. We get `n1_alloc`: an array of length K summing to n1.",
   "id": "c7c2ae3f8cef0d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:27.782585Z",
     "start_time": "2025-06-21T17:49:27.776388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "boundary_probs = compute_boundary_probs(policies, R, H)\n",
    "n1_alloc = allocate_wave(boundary_probs, n1)\n",
    "print(f\"First‐wave allocation sums to {int(n1_alloc.sum())} (should be {n1}).\")"
   ],
   "id": "6dcc0a9d2d342815",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First‐wave allocation sums to 500 (should be 500).\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Simulating first-wave outcomes",
   "id": "db2cf32df91f077f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We generate a np.array `beta` of true effects for each node. We pass our lattice `policies`, `M` and `R`, and then specify a `kind` of underlying causal model.\n",
    "\n",
    "There are a range of options, all of which are continuous and non-trivial: they exhibit locally correlated effects and avoid brittle cancellations in effects. The options range from simple (polynomial, gaussian, basic interaction) to complex (radial basis function, mimic of a simple neural-net-like function)"
   ],
   "id": "783d2bf35aa2605f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:28.324170Z",
     "start_time": "2025-06-21T17:49:28.321776Z"
    }
   },
   "cell_type": "code",
   "source": "beta = get_beta_underlying_causal(policies, M, R, kind=\"gauss_sin\")",
   "id": "37f3b09738cfdc4e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:28.626067Z",
     "start_time": "2025-06-21T17:49:28.623711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Not in use: different distribution for each true pool from a random 'true' partition sigma_true. Not used in this simulation due to our specifications on the underlying causal model (e.g. continuous, locally correlated effects, etc). Also needs changes on how it constructs a true partition.\n",
    "\n",
    "# partition_seed = 123\n",
    "# sigma_true, pi_pools_true, pi_policies_true = generate_true_partition(policies, R,random_seed=partition_seed)\n",
    "# beta = get_beta_piecewise(policies, sigma_true, pi_pools_true, pi_policies_true, 0.5, 1, 10)"
   ],
   "id": "c0124dca96a59a16",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Get outcomes**: we now track the first-wave assignment and generate the outcomes with additional noise",
   "id": "96414d2d89e71d3c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:29.847057Z",
     "start_time": "2025-06-21T17:49:29.840811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now build first-wave assignment vector D\n",
    "policies = np.array(enumerate_policies(M, R))  # (K, M)\n",
    "D1 = assign_treatments(n1_alloc)  # (N1, M)\n",
    "print(\"D1 shape:\", D1.shape)\n",
    "N1 = D1.shape[0]\n",
    "print(\"Length of D1:\", N1)  # should equal sum n1_alloc == n1"
   ],
   "id": "4cb7d7c5a1785390",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1 shape: (500,)\n",
      "Length of D1: 500\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:30.199783Z",
     "start_time": "2025-06-21T17:49:30.195470Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate outcomes y1\n",
    "sigma_noise = 5\n",
    "outcome_seed = 53\n",
    "y1 = generate_outcomes(D=D1, beta=beta, sigma_noise=sigma_noise, random_seed=outcome_seed)\n",
    "print(\"Overall mean outcome:\", np.mean(y1))\n",
    "print(\"Overall std outcome:\", np.std(y1))"
   ],
   "id": "a9a34a6d63a9e449",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean outcome: -0.04486496781745926\n",
      "Overall std outcome: 5.353826860373732\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. RPS for profiles with data",
   "id": "d65ec763ab104f39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We now search for the optimal theta as given by a normalized loss and chosen epsilon. Need to already specify H and the regularization parameter.",
   "id": "30fbf3ae778f228f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:31.154777Z",
     "start_time": "2025-06-21T17:49:31.151839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lambda_r = 0.3\n",
    "eps = 0.05 # chosen tolerance"
   ],
   "id": "bf3efc3328c7bf10",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:31.459444Z",
     "start_time": "2025-06-21T17:49:31.455951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from rashomon.hasse import enumerate_policies, enumerate_profiles, policy_to_profile\n",
    "from rashomon.aggregate import (\n",
    "    RAggregate_profile,\n",
    "    subset_data,\n",
    "    find_profile_lower_bound\n",
    ")\n",
    "from rashomon import loss"
   ],
   "id": "6dbeb16e2bb5cc0f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:31.811824Z",
     "start_time": "2025-06-21T17:49:31.807514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Enumerate profiles and map policies to each\n",
    "profiles, profile_map = enumerate_profiles(M)\n",
    "all_policies = enumerate_policies(M, R_vec)\n",
    "\n",
    "profile_to_policies = {}\n",
    "profile_to_indices = {}\n",
    "for i, pol in enumerate(all_policies):\n",
    "    pid = profile_map[policy_to_profile(pol)]\n",
    "    profile_to_policies.setdefault(pid, []).append(pol)\n",
    "    profile_to_indices.setdefault(pid, []).append(i)"
   ],
   "id": "d30d48d97739eb63",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We now filter for the profiles just with any data.",
   "id": "b79afcee8eee6bfa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:32.600683Z",
     "start_time": "2025-06-21T17:49:32.592697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2: Filter profiles with data and compute normalized lower-bound losses\n",
    "valid_pids = []\n",
    "lb_k = []  # normalized lower-bound loss for each valid profile\n",
    "\n",
    "for pid, profile in enumerate(profiles):\n",
    "    Dk, yk = subset_data(D1, y1, profile_to_indices[pid])\n",
    "    if Dk is None:\n",
    "        continue\n",
    "    mask = np.array(profile, dtype=bool)\n",
    "    reduced_policies = [tuple(np.array(p)[mask]) for p in profile_to_policies[pid]]\n",
    "    pm = loss.compute_policy_means(Dk, yk, len(reduced_policies))\n",
    "    raw_lb = find_profile_lower_bound(Dk, yk, pm)\n",
    "    lb_k.append(raw_lb / N1)\n",
    "    valid_pids.append(pid)\n",
    "\n",
    "lb_k = np.array(lb_k)                   # array of normalized lower bounds\n",
    "best_loss = lb_k.min()                 # best profile loss\n",
    "total_lb = lb_k.sum()\n",
    "theta_global = total_lb * (1 + eps) # Theta is in reference to total loss here, not a relative value\n",
    "print(f\"best_loss = {best_loss:.5f}\")\n",
    "print(f\"theta_global = {theta_global:.5f}\")"
   ],
   "id": "8e89eb7377549fa2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_loss = 0.83288\n",
      "theta_global = 26.40538\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We now construct the RPS for each profile with data from our first allocation.",
   "id": "d090de1185f966ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:33.480673Z",
     "start_time": "2025-06-21T17:49:33.405774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "R_profiles = []\n",
    "loss_args = []\n",
    "\n",
    "for i, pid in enumerate(valid_pids):\n",
    "    profile_mask = np.array(profiles[pid], dtype=bool)\n",
    "    M_k = profile_mask.sum()\n",
    "    R_k = R_vec[profile_mask]\n",
    "\n",
    "    Dk, yk = subset_data(D1, y1, profile_to_indices[pid])\n",
    "    reduced_policies = [tuple(np.array(p)[profile_mask]) for p in profile_to_policies[pid]]\n",
    "    pm = loss.compute_policy_means(Dk, yk, len(reduced_policies))\n",
    "\n",
    "    theta_k = max(0.0, theta_global - (total_lb - lb_k[i]))\n",
    "\n",
    "    print(f\"Calling RAggregate_profile on profile {pid}, M_k={M_k}, len(policies)={len(reduced_policies)}, theta_k={theta_k:.5f}\")\n",
    "    print(f\": lower_bound: {lb_k[i]:.5f}, theta_k: {theta_k:.5f}\")\n",
    "\n",
    "    rp = RAggregate_profile(\n",
    "        M=M_k,\n",
    "        R=R_k,\n",
    "        H=H,\n",
    "        D=Dk,\n",
    "        y=yk,\n",
    "        theta=theta_k,\n",
    "        profile=tuple(profiles[pid]),\n",
    "        reg=lambda_r,\n",
    "        policies=reduced_policies,\n",
    "        policy_means=pm,\n",
    "        normalize=N1\n",
    "    )\n",
    "\n",
    "    print(f\": RPS size for profile {pid}: {len(rp)}\")\n",
    "    if len(rp) > 0:\n",
    "        R_profiles.append(rp)\n",
    "        loss_args.append((Dk, yk, reduced_policies, pm))"
   ],
   "id": "d864d078a9c1d824",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling RAggregate_profile on profile 1, M_k=1, len(policies)=3, theta_k=2.52183\n",
      ": lower_bound: 1.26443, theta_k: 2.52183\n",
      ": RPS size for profile 1: 4\n",
      "Calling RAggregate_profile on profile 2, M_k=1, len(policies)=3, theta_k=2.09028\n",
      ": lower_bound: 0.83288, theta_k: 2.09028\n",
      ": RPS size for profile 2: 4\n",
      "Calling RAggregate_profile on profile 3, M_k=2, len(policies)=9, theta_k=3.99993\n",
      ": lower_bound: 2.74253, theta_k: 3.99993\n",
      ": RPS size for profile 3: 0\n",
      "Calling RAggregate_profile on profile 4, M_k=1, len(policies)=3, theta_k=2.46270\n",
      ": lower_bound: 1.20530, theta_k: 2.46270\n",
      ": RPS size for profile 4: 4\n",
      "Calling RAggregate_profile on profile 5, M_k=2, len(policies)=9, theta_k=5.17228\n",
      ": lower_bound: 3.91488, theta_k: 5.17228\n",
      ": RPS size for profile 5: 0\n",
      "Calling RAggregate_profile on profile 6, M_k=2, len(policies)=9, theta_k=4.32047\n",
      ": lower_bound: 3.06307, theta_k: 4.32047\n",
      ": RPS size for profile 6: 0\n",
      "Calling RAggregate_profile on profile 7, M_k=3, len(policies)=27, theta_k=13.38227\n",
      ": lower_bound: 12.12488, theta_k: 13.38227\n",
      ": RPS size for profile 7: 0\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:46.126332Z",
     "start_time": "2025-06-21T17:49:46.114751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute loss only for nonempty profile RPSs\n",
    "for rp, (Dk, yk, policies_k, pm_k) in zip(R_profiles, loss_args):\n",
    "    rp.calculate_loss(Dk, yk, policies_k, pm_k, lambda_r, normalize=N1)"
   ],
   "id": "3fa23bf50b57be30",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Construct the full RPS",
   "id": "39a3c974e7fa947e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We demonstrate the creation of the full RPS from the profile-specific partitions.",
   "id": "bd9c8723d19ab924"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:50.215922Z",
     "start_time": "2025-06-21T17:49:50.210121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Data checks\n",
    "D = np.asarray(D1)\n",
    "y = np.asarray(y1)\n",
    "if D.ndim != 1:\n",
    "    raise ValueError(f\"D should be 1D (policy indices), got shape {D.shape}\")\n",
    "if y.ndim != 1:\n",
    "    y = y.ravel()\n",
    "N = len(D)\n",
    "if len(y) != N:\n",
    "    raise ValueError(f\"y and D must have same length: got {len(y)} and {N}\")\n",
    "\n",
    "\n",
    "# Enumerate all policies and profiles\n",
    "profiles, profile_map = enumerate_profiles(M)\n",
    "all_policies = enumerate_policies(M, R_vec)\n",
    "policy_to_pid = {tuple(pol): profile_map[policy_to_profile(pol)] for pol in all_policies}\n",
    "policy_to_indices = {pid: [] for pid in range(len(profiles))}\n",
    "for i, pol in enumerate(all_policies):\n",
    "    pid = policy_to_pid[tuple(pol)]\n",
    "    policy_to_indices[pid].append(i)\n"
   ],
   "id": "ce6fb0f1bee546f2",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:51.816838Z",
     "start_time": "2025-06-21T17:49:51.806681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 2: Identify active profiles and compute lower bounds\n",
    "valid_pids = []\n",
    "lb_k = []\n",
    "for pid, profile in enumerate(profiles):\n",
    "    indices = policy_to_indices[pid]\n",
    "    idx_mask = np.isin(D, indices)\n",
    "    if np.sum(idx_mask) > 0:\n",
    "        Dk_policyidx = D[idx_mask]         # Global policy indices for this profile\n",
    "        yk = y[idx_mask]\n",
    "        profile_mask = np.array(profile, dtype=bool)\n",
    "        # Map to reduced policies (profile-local tuples)\n",
    "        policies_k = [tuple(np.array(all_policies[pol_idx])[profile_mask]) for pol_idx in Dk_policyidx]\n",
    "        policies_k_unique = list(sorted(set(policies_k)))\n",
    "        # Build tuple->local index mapping for this profile\n",
    "        tuple_to_local_idx = {p: i for i, p in enumerate(policies_k_unique)}\n",
    "        Dk_local = np.array([tuple_to_local_idx[p] for p in policies_k])\n",
    "        pm = loss.compute_policy_means(Dk_local, yk, len(policies_k_unique))\n",
    "        raw_lb = find_profile_lower_bound(Dk_local, yk.reshape(-1, 1), pm)\n",
    "        lb_k.append(raw_lb / N)\n",
    "        valid_pids.append(pid)\n",
    "\n",
    "    else:\n",
    "        lb_k.append(0.0)\n",
    "\n",
    "lb_k_arr = np.array(lb_k)\n",
    "total_lb = lb_k_arr.sum()\n",
    "theta_global = total_lb * (1 + eps)\n",
    "print(f\"Observed profiles: {valid_pids}\")\n",
    "print(f\"Threshold: {theta_global:.5f}\")\n",
    "print(f\"Per-profile lower bounds: {lb_k_arr}\")"
   ],
   "id": "7be58726134ef2ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed profiles: [1, 2, 3, 4, 5, 6, 7]\n",
      "Threshold: 26.40538\n",
      "Per-profile lower bounds: [ 0.          1.26442926  0.83287935  2.74253134  1.20530388  3.91488388\n",
      "  3.06307379 12.12487562]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:49:52.824590Z",
     "start_time": "2025-06-21T17:49:52.756860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3: Build per-profile RashomonSets (always using local indices!)\n",
    "R_profiles = []\n",
    "for i, pid in enumerate(valid_pids):\n",
    "    indices = policy_to_indices[pid]\n",
    "    idx_mask = np.isin(D, indices)\n",
    "    Dk_policyidx = D[idx_mask]\n",
    "    yk = y[idx_mask]\n",
    "    profile_mask = np.array(profiles[pid], dtype=bool)\n",
    "    M_k = profile_mask.sum()\n",
    "    R_k = R_vec[profile_mask]\n",
    "    policies_k = [tuple(np.array(all_policies[pol_idx])[profile_mask]) for pol_idx in Dk_policyidx]\n",
    "    policies_k_unique = list(sorted(set(policies_k)))\n",
    "    tuple_to_local_idx = {p: j for j, p in enumerate(policies_k_unique)}\n",
    "    Dk_local = np.array([tuple_to_local_idx[p] for p in policies_k])\n",
    "    pm = loss.compute_policy_means(Dk_local, yk, len(policies_k_unique))\n",
    "    theta_k = max(0.0, theta_global - (total_lb - lb_k[pid]))\n",
    "    print(f\"Profile {pid}: M_k={M_k}, #policies={len(policies_k_unique)}, theta_k={theta_k:.5f}\")\n",
    "    rp = RAggregate_profile(\n",
    "        M=M_k,\n",
    "        R=R_k,\n",
    "        H=H,\n",
    "        D=Dk_local.reshape(-1, 1),          # 1D array of local indices\n",
    "        y=yk.reshape(-1, 1),                # 1D array of outcomes\n",
    "        theta=theta_k,\n",
    "        profile=tuple(profiles[pid]),\n",
    "        reg=lambda_r,\n",
    "        policies=policies_k_unique,\n",
    "        policy_means=pm,\n",
    "        normalize=N\n",
    "    )\n",
    "    print(f\": RPS size: {len(rp)}\")\n",
    "    R_profiles.append(rp)"
   ],
   "id": "de43f894dc57d2fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile 1: M_k=1, #policies=2, theta_k=2.52183\n",
      ": RPS size: 4\n",
      "Profile 2: M_k=1, #policies=2, theta_k=2.09028\n",
      ": RPS size: 4\n",
      "Profile 3: M_k=2, #policies=8, theta_k=3.99993\n",
      ": RPS size: 3\n",
      "Profile 4: M_k=1, #policies=2, theta_k=2.46270\n",
      ": RPS size: 4\n",
      "Profile 5: M_k=2, #policies=8, theta_k=5.17228\n",
      ": RPS size: 0\n",
      "Profile 6: M_k=2, #policies=8, theta_k=4.32047\n",
      ": RPS size: 3\n",
      "Profile 7: M_k=3, #policies=26, theta_k=13.38227\n",
      ": RPS size: 0\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:50:13.335480Z",
     "start_time": "2025-06-21T17:50:13.325642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import product\n",
    "# Step 4: Cross-product of valid RashomonSets (partial Rashomon set)\n",
    "nonempty_idx = [i for i, rp in enumerate(R_profiles) if len(rp) > 0]\n",
    "nonempty_profiles = [R_profiles[i] for i in nonempty_idx]\n",
    "R_set_partial = list(product(*[range(len(rp)) for rp in nonempty_profiles]))\n",
    "print(f\"Found {len(R_set_partial)} Rashomon sets across {len(nonempty_profiles)} nonempty profiles.\")\n",
    "print(f\"Nonempty profile indices: {nonempty_idx}\")\n",
    "print(f\"Total profiles (partitions): {len(R_profiles)}\")\n",
    "print(f\"Profiles with nonempty RPS: {len(nonempty_profiles)}\")\n"
   ],
   "id": "a782f428c90f72f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 576 Rashomon sets across 5 nonempty profiles.\n",
      "Nonempty profile indices: [0, 1, 2, 3, 5]\n",
      "Total profiles (partitions): 7\n",
      "Profiles with nonempty RPS: 5\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now set this up in a larger wrapper function too:",
   "id": "81dfe39194dc15fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:50:15.383268Z",
     "start_time": "2025-06-21T17:50:15.302855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from observed_RPS import observed_rps\n",
    "R_set_partial, R_profiles, nonempty_idx, profiles = observed_rps(\n",
    "    M, R_vec, H, D1, y1, lambda_r, eps=0.05\n",
    ")"
   ],
   "id": "7fe769f6a7cac52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile 1: M_k=1, #policies=2, theta_k=2.52183\n",
      "Profile 2: M_k=1, #policies=2, theta_k=2.09028\n",
      "Profile 3: M_k=2, #policies=8, theta_k=3.99993\n",
      "Profile 4: M_k=1, #policies=2, theta_k=2.46270\n",
      "Profile 5: M_k=2, #policies=8, theta_k=5.17228\n",
      "Profile 6: M_k=2, #policies=8, theta_k=4.32047\n",
      "Profile 7: M_k=3, #policies=26, theta_k=13.38227\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We demonstrate a main wrapper call, as we would use from the original Rashomon module, but we note that the function operates unexpectedly because we don't have data for a number of the profiles. (We end up with an empty Rashomon Partition Set).",
   "id": "550fb5a98dfcbeb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:50:22.991110Z",
     "start_time": "2025-06-21T17:50:22.002208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Doesn't work!! Because only have data on a small subspace, and quits out when we can't make a pooling decision\n",
    "# Call main RAggregate function\n",
    "R_set_empty, R_profiles_empty = RAggregate(\n",
    "    M=M,\n",
    "    R=R_vec,\n",
    "    H=H,\n",
    "    D=D1,\n",
    "    y=y1,\n",
    "    theta=theta_global,\n",
    "    reg=lambda_r,\n",
    "    verbose=True,\n",
    ")"
   ],
   "id": "c61165e5ea76d402",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping profile (0, 0, 0)\n",
      "(0, 0, 1) 2.5218281187720244\n",
      "Adaptive\n",
      "Profile (0, 0, 1) took 0.00011610984802246094 s adaptively\n",
      "Profile (0, 0, 1) has 0 objects in Rashomon set\n",
      "(0, 1, 0) 2.09027820243983\n",
      "Adaptive\n",
      "Profile (0, 1, 0) took 4.76837158203125e-05 s adaptively\n",
      "Profile (0, 1, 0) has 0 objects in Rashomon set\n",
      "(0, 1, 1) 3.9999302008722566\n",
      "Adaptive\n",
      "Profile (0, 1, 1) took 4.792213439941406e-05 s adaptively\n",
      "Profile (0, 1, 1) has 0 objects in Rashomon set\n",
      "(1, 0, 0) 2.4627027387679625\n",
      "Adaptive\n",
      "Profile (1, 0, 0) took 3.0994415283203125e-05 s adaptively\n",
      "Profile (1, 0, 0) has 0 objects in Rashomon set\n",
      "(1, 0, 1) 5.172282732013944\n",
      "Adaptive\n",
      "Profile (1, 0, 1) took 3.5762786865234375e-05 s adaptively\n",
      "Profile (1, 0, 1) has 0 objects in Rashomon set\n",
      "(1, 1, 0) 4.320472649662342\n",
      "Adaptive\n",
      "Profile (1, 1, 0) took 3.62396240234375e-05 s adaptively\n",
      "Profile (1, 1, 0) has 0 objects in Rashomon set\n",
      "(1, 1, 1) 13.382274480921094\n",
      "Adaptive\n",
      "Profile (1, 1, 1) took 4.57763671875e-05 s adaptively\n",
      "Profile (1, 1, 1) has 0 objects in Rashomon set\n",
      "Finding feasible combinations\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Second-wave allocation",
   "id": "e216bc08a51b126c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3542cb980c3cfd85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "dd9c36846b7bd21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a59143484b9d83dc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
